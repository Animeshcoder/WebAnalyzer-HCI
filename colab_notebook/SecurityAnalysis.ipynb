{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1376,
     "status": "ok",
     "timestamp": 1726637707915,
     "user": {
      "displayName": "Animesh Awasthi",
      "userId": "06245988644800937794"
     },
     "user_tz": -330
    },
    "id": "C7HxsK2PkEN9",
    "outputId": "0fcee8de-f026-4d7a-901c-855db91c9dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HTTPS is enabled.\n",
      "Login Pages Found: []\n",
      "Signup Pages Found: []\n",
      "⚠️ Session ID may be too short or predictable, leading to security risks.\n",
      "⚠️ Unexpected response. Review access control measures.\n",
      "✅ Strict-Transport-Security is properly set.\n",
      "✅ Content-Security-Policy is properly set.\n",
      "✅ X-Content-Type-Options is properly set.\n",
      "✅ X-Frame-Options is properly set.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to verify if HTTPS is being used\n",
    "def verify_https(site_url):\n",
    "    if site_url.startswith('https'):\n",
    "        print(\"✅ HTTPS is enabled.\")\n",
    "    else:\n",
    "        print(\"⚠️ HTTPS is not enabled. Consider using HTTPS for better security.\")\n",
    "\n",
    "# Function to detect login and registration links\n",
    "def detect_auth_links(website_url):\n",
    "    response = requests.get(website_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    login_pages = []\n",
    "    signup_pages = []\n",
    "\n",
    "    for anchor in soup.find_all('a', href=True):\n",
    "        href = anchor['href']\n",
    "        if 'login' in href.lower():\n",
    "            login_pages.append(href)\n",
    "        if 'signup' in href.lower() or 'register' in href.lower():\n",
    "            signup_pages.append(href)\n",
    "\n",
    "    return login_pages, signup_pages\n",
    "\n",
    "# Function to evaluate login form fields\n",
    "def evaluate_login_form(page_url):\n",
    "    response = requests.get(page_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    fields = soup.find_all('input')\n",
    "    for field in fields:\n",
    "        print(f\"Field Name: {field.get('name')}, Type: {field.get('type')}\")\n",
    "\n",
    "    captcha_detected = soup.find('div', {'class': 'g-recaptcha'})\n",
    "    if captcha_detected:\n",
    "        print(\"✅ CAPTCHA is present, improving security.\")\n",
    "    else:\n",
    "        print(\"⚠️ CAPTCHA is missing, increasing vulnerability to brute-force attacks.\")\n",
    "\n",
    "# Function to examine session cookies and authentication tokens\n",
    "def examine_cookies_tokens(session_obj, login_page, user, pwd):\n",
    "    credentials = {\n",
    "        'username': user,\n",
    "        'password': pwd\n",
    "    }\n",
    "    login_attempt = session_obj.post(login_page, data=credentials)\n",
    "\n",
    "    for cookie in session_obj.cookies:\n",
    "        print(f\"Cookie Name: {cookie.name}, Secure: {cookie.secure}, HttpOnly: {cookie.has_nonstandard_attr('HttpOnly')}\")\n",
    "\n",
    "    token_check = login_attempt.headers.get('Authorization')\n",
    "    if token_check and 'Bearer' in token_check:\n",
    "        print(\"✅ JWT token detected for authentication.\")\n",
    "    else:\n",
    "        print(\"⚠️ JWT token not found. Review authentication mechanism.\")\n",
    "\n",
    "# Function to validate session management practices\n",
    "def validate_session(session_obj):\n",
    "    session_token = session_obj.cookies.get('sessionid')\n",
    "    if session_token and len(session_token) > 20:\n",
    "        print(\"✅ Session ID is sufficiently long and random.\")\n",
    "    else:\n",
    "        print(\"⚠️ Session ID may be too short or predictable, leading to security risks.\")\n",
    "\n",
    "# Function to conduct authorization validation\n",
    "def check_authorization(session_obj, secure_url):\n",
    "    secure_response = session_obj.get(secure_url)\n",
    "\n",
    "    if secure_response.status_code == 403:\n",
    "        print(\"✅ Access correctly restricted based on user roles.\")\n",
    "    elif secure_response.status_code == 200:\n",
    "        print(\"⚠️ Access granted. Ensure authorization checks are enforced correctly.\")\n",
    "    else:\n",
    "        print(\"⚠️ Unexpected response. Review access control measures.\")\n",
    "\n",
    "# Function to review HTTP security headers\n",
    "def evaluate_http_headers(http_response):\n",
    "    headers = http_response.headers\n",
    "    security_policies = [\n",
    "        'Strict-Transport-Security',\n",
    "        'Content-Security-Policy',\n",
    "        'X-Content-Type-Options',\n",
    "        'X-Frame-Options'\n",
    "    ]\n",
    "    for policy in security_policies:\n",
    "        if policy in headers:\n",
    "            print(f\"✅ {policy} is properly set.\")\n",
    "        else:\n",
    "            print(f\"⚠️ {policy} is missing. Consider implementing it.\")\n",
    "\n",
    "# Main function to execute security checks\n",
    "def main():\n",
    "    target_url = 'https://amazon.in'  # Change this to the target site\n",
    "    session = requests.Session()\n",
    "\n",
    "    # Step 1: Verify HTTPS security\n",
    "    verify_https(target_url)\n",
    "\n",
    "    # Step 2: Identify authentication-related links\n",
    "    logins, signups = detect_auth_links(target_url)\n",
    "    print(f\"Login Pages Found: {logins}\")\n",
    "    print(f\"Signup Pages Found: {signups}\")\n",
    "\n",
    "    # Step 3: Evaluate login form if login page exists\n",
    "    if logins:\n",
    "        evaluate_login_form(target_url + logins[0])\n",
    "\n",
    "    # Step 4: Analyze authentication cookies and tokens\n",
    "    if logins:\n",
    "        user_id = 'sample_user'  # Replace with actual username\n",
    "        user_pwd = 'sample_password'  # Replace with actual password\n",
    "        examine_cookies_tokens(session, target_url + logins[0], user_id, user_pwd)\n",
    "\n",
    "    # Step 5: Validate session management security\n",
    "    validate_session(session)\n",
    "\n",
    "    # Step 6: Test authorization restrictions\n",
    "    restricted_area = target_url + '/restricted'  # Modify with actual protected resource\n",
    "    check_authorization(session, restricted_area)\n",
    "\n",
    "    # Step 7: Examine HTTP security headers\n",
    "    http_response = session.get(target_url)\n",
    "    evaluate_http_headers(http_response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1726638237323,
     "user": {
      "displayName": "Animesh Awasthi",
      "userId": "06245988644800937794"
     },
     "user_tz": -330
    },
    "id": "T94kNxmJp3pV",
    "outputId": "becce9fb-0f96-478c-f7d0-e7bd20cc1bc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails: []\n",
      "Phone Numbers: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-c5d4151b2cff>:18: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  privacy_policy = soup.find('a', href=True, text=re.compile(r'Privacy Policy', re.I))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "url = 'https://sitare.org'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Extract emails\n",
    "emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', soup.text)\n",
    "print('Emails:', emails)\n",
    "\n",
    "# Extract phone numbers\n",
    "phone_numbers = re.findall(r'\\b\\d{10}\\b', soup.text)\n",
    "print('Phone Numbers:', phone_numbers)\n",
    "\n",
    "# Extract privacy policy URL\n",
    "privacy_policy = soup.find('a', href=True, text=re.compile(r'Privacy Policy', re.I))\n",
    "if privacy_policy:\n",
    "    privacy_policy_url = privacy_policy['href']\n",
    "    print(f'Privacy Policy URL: {privacy_policy_url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7pilyvlzoogT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMU8k6Oac+wVQH1xPMV+OFd",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
